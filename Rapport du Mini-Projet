# Mini-Projet d’Apprentissage Supervisé

## Régression Linéaire et Régression Logistique

**Master 1 Intelligence Artificielle (M1 IA)**
**Année universitaire : 2025–2026**

**Étudiant : Mohamed Mahmoud Said**
**Matricule : C34666**

---

## 1. Introduction

L’apprentissage supervisé est une branche fondamentale du Machine Learning qui consiste à entraîner un modèle à partir de données étiquetées afin de prédire une variable cible.
L’objectif de ce mini-projet est de consolider les concepts théoriques vus en cours à travers l’implémentation pratique de deux modèles essentiels :

* La **régression linéaire**, utilisée pour prédire des valeurs continues.
* La **régression logistique**, utilisée pour les problèmes de classification.

Ce travail permet de comprendre les différentes étapes d’un pipeline de Machine Learning : préparation des données, modélisation, entraînement, évaluation et interprétation des résultats.

---

## 2. Régression Linéaire

### 2.1 Présentation des données

Pour la régression linéaire, un jeu de données de type régression a été utilisé, contenant plusieurs variables explicatives ainsi qu’une variable cible numérique.
Avant l’entraînement du modèle, une analyse exploratoire des données a été réalisée afin de mieux comprendre les relations entre les variables.

---

### 2.2 Analyse des corrélations

Une **matrice de corrélation** a été construite et visualisée à l’aide d’une **heatmap**.
Cette étape permet d’identifier les variables les plus corrélées à la variable cible et d’évaluer la redondance éventuelle entre les variables explicatives.

Les résultats montrent que certaines variables présentent une corrélation significative avec la variable cible, ce qui justifie leur utilisation dans le modèle de régression.

---

### 2.3 Modélisation mathématique

Le modèle de régression linéaire est formalisé par l’équation suivante :

[
y = \beta_0 + \sum_{i=1}^{n} \beta_i x_i + \varepsilon
]

où :

* ( y ) est la variable cible,
* ( x_i ) sont les variables explicatives,
* ( \beta_i ) sont les coefficients du modèle,
* ( \varepsilon ) représente l’erreur.

Le modèle a été entraîné à l’aide de la bibliothèque **scikit-learn**.

---

### 2.4 Évaluation du modèle

Les performances du modèle ont été évaluées à l’aide des métriques suivantes :

* **Coefficient de détermination (R²)** : mesure la capacité du modèle à expliquer la variance des données.
* **Erreur quadratique moyenne (MSE)** : mesure l’écart moyen entre les valeurs réelles et les valeurs prédites.

Les résultats obtenus montrent que le modèle est capable de prédire la variable cible avec une précision satisfaisante.

---

### 2.5 Interprétation des coefficients

L’analyse des coefficients ( \beta_i ) permet de mesurer l’importance de chaque variable explicative.
Les variables ayant des coefficients élevés ont un impact plus important sur la prédiction, tandis que celles avec des coefficients faibles influencent peu le résultat final.

---

## 3. Régression Logistique

### 3.1 Présentation des données

Pour la régression logistique, le dataset **Iris**, disponible dans la bibliothèque scikit-learn, a été utilisé.
Le problème a été transformé en une **classification binaire**, en distinguant une classe spécifique des autres.

---

### 3.2 Préparation des données

Les données ont été divisées en ensembles d’entraînement et de test.
Une **normalisation des variables** a été effectuée afin d’améliorer la convergence du modèle et d’assurer une meilleure stabilité numérique.

---

### 3.3 Modélisation

La régression logistique modélise la probabilité d’appartenance à une classe à l’aide de la fonction sigmoïde :

[
P(y=1|x) = \frac{1}{1 + e^{-z}}
]

où ( z ) est une combinaison linéaire des variables d’entrée.

---

### 3.4 Évaluation du modèle

Le modèle a été évalué à l’aide des métriques suivantes :

* **Matrice de confusion**
* **Accuracy**
* **Précision**
* **Recall**

Les résultats montrent que le modèle de régression logistique permet de distinguer efficacement les deux classes, avec de bonnes performances globales.

---

## 4. Conclusion

Ce mini-projet a permis de mettre en pratique les concepts fondamentaux de l’apprentissage supervisé.
La régression linéaire s’est révélée efficace pour la prédiction de valeurs continues, tandis que la régression logistique a montré de bonnes performances pour la classification binaire.

Ce travail a renforcé la compréhension des étapes essentielles du Machine Learning, depuis l’analyse des données jusqu’à l’évaluation des modèles, et constitue une base solide pour l’étude de modèles plus avancés.

---

## 5. Outils et Technologies

* Python
* NumPy
* Pandas
* Matplotlib / Seaborn
* Scikit-learn
* Google Colab
* GitHub
